'''#
Okay I do not recommend using GridSearchCV, while yes, it is a really good idea on paper to get
Python to just do the hyper parameter tuning for you.
But! It takes way too long if you're using a normal laptop, this is only workable on a machine
With more power and memoroy that can run such a long program like this.
I still don't even know the results, even running just one model can take an entire day.
#'''

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import accuracy_score 
import pandas as pd

import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("/home/a/notebook/machinelearning/malwareDetection/dataset/dataset_malwares.csv")
# df.head()

# df.info()

dropped_df = df.drop(['Name', 'Machine', 'TimeDateStamp', 'Malware'], axis = 1)

X = dropped_df
y = df['Malware']

X_train, X_test, y_train, y_test = train_test_split(X, 
                                                    y, 
                                                    random_state = 42, 
                                                    test_size = 0.2,
                                                    stratify = y)

# print("Number of used feature: ", X_train.shape[1])

# Gradiet Boosting Classifier Gird Search

GB_Model = GradientBoostingClassifier()
GB_Grid = {
    'loss': ['log_loss', 'deviance', 'exponential'],
    'criterion': ['friedman_mse', 'squared_error'],
    'learning_rate': [0.1, 0.2, 0.3, 0.4],
    'n_estimators': [50, 100, 150, 200],
    'random_state': [None, 42, 70, 100],
    'max_depth': [None, 8, 16, 24, 32]
}

GB_Search = GridSearchCV(estimator = GB_Model,
                         param_grid = GB_Grid,
                         cv = 5,
                         scoring = 'accuracy')

GB_Search.fit(X_train, y_train)

Best_GB_Param = GB_Search.best_params_
Best_GB_Model = GB_Search.best_estimator_

y_pred = Best_GB_Model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Bagging Grid Search

Bag_Model = BaggingClassifier()
Bag_Grid = {
    'n_estimators': [10, 20, 30, 40],
    'max_samples': [1.0, 2.0, 3.0, 4.0],
    'random_state': [None, 42, 70, 100],
    'oob_score': [True],
    'bootstrap': [True],
    'bootstrap_features': [True],
    'max_features': [1.0, 2.0, 3.0, 4.0]
}

Bag_Search = GridSearchCV(estimator = Bag_Model,
                            param_grid = Bag_Grid,
                            cv = 5,
                            scoring = 'accuracy')

Bag_Search.fit(X_train, y_train)

Best_Bag_Param = Bag_Search.best_params_
Best_Bag_Model = Bag_Search.best_estimator_

y_pred = Best_Bag_Model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Ada Boost Gird Search

Ada_Model = AdaBoostClassifier()
Ada_Grid = {
    'algorith': ['SAMME.R', 'SAMME'],
    'n_estimators': [50, 100, 150, 200],
    'random_state': [None, 42, 70, 100],
    'lerning_rate': [1.0, 2.0, 3.0, 4.0],
    'base_estimator': [None]
}

Ada_Search = GridSearchCV(estimator = Ada_Model,
                          param_grid = Ada_Grid,
                          cv = 5,
                          scoring = 'accuracy')

Ada_Search.fit(X_train, y_train)

Best_Ada_Param = Ada_Search.best_params_
Best_Ada_Model = Ada_Search.best_estimator_

y_pred = Best_Ada_Model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")